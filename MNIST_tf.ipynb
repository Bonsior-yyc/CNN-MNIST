{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "MNIST-tf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1o3VoPpmlGMO",
    "colab_type": "text"
   },
   "source": [
    "## MNIST Tensorflow\n",
    "\n",
    "#### 在运行之前，应满足如下库的需求，并在工作区下载data源文件"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lfGyuvSklJnp",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "outputId": "6af66eca-4280-40fe-a599-c1c79a8f10b6"
   },
   "source": [
    "!pip3 install tensorflow-gpu==2.0.0 \n"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.27.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.1.8)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (2.0.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.17.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (2.0.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0) (45.2.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.7.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.21.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BVJndMCurqG3",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "95960ae1-bb8a-48bc-c862-755f4732c518",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# 检验gpu\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3h6eQQpmPX5",
    "colab_type": "text"
   },
   "source": [
    "### 根据数据存放位置，修改配置信息。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x9oSFIDqmSh-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 需要配置 根据文件存放位置\n",
    "train_data_file = '/content/drive/My Drive/CNN-MNIST/data/train/train-images-idx3-ubyte'\n",
    "train_label_file = '/content/drive/My Drive/CNN-MNIST/data/train/train-labels-idx1-ubyte'\n",
    "test_data_file = '/content/drive/My Drive/CNN-MNIST/data/test/t10k-images-idx3-ubyte'\n",
    "test_label_file = '/content/drive/My Drive/CNN-MNIST/data/test/t10k-labels-idx1-ubyte'\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KEGKx24mbXE",
    "colab_type": "text"
   },
   "source": [
    "#### 可视化工具，包括进度条和图片显示工具"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y1JPFvObmcyk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 同pytorch中的注释\n",
    "import time\n",
    "class Progress_bar(object):\n",
    "    def __init__(self):\n",
    "        self.start = time.perf_counter()\n",
    "        self.last_update = time.perf_counter()\n",
    "\n",
    "    def bar(self, index, length, script, batch=1):\n",
    "        index = index * batch\n",
    "        if length - index < batch:\n",
    "            index = length-1\n",
    "        percentage = (index+1) / length\n",
    "        progress = list('..........................')\n",
    "        progress[(index+1) * 25//length] = '>'\n",
    "        progress[:(index+1) * 25//length] = '=' * ((index+1) * 25//length + 1)\n",
    "        progress = ''.join(progress)\n",
    "        end_time = time.perf_counter()\n",
    "        print(\"\\r{}: {}  time left:{:.2f}s {}/{}  {:.2f} {} time cost:{:.2f}s \"\n",
    "              .format(script,\n",
    "                      progress,\n",
    "                      (end_time - self.start) / percentage * (1 - percentage),\n",
    "                      (index+1), length, percentage * 100, \"%\", end_time - self.start), end='')\n",
    "        self.last_update = time.perf_counter()\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P_QdCXXdmfL3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 同Pytorch中的注释\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def show_image(array, rows=1, cols=1):\n",
    "    if rows * cols == 1:\n",
    "        plt.figure()\n",
    "        plt.imshow(array, cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                index = row * cols + col \n",
    "                plt.subplot(rows, cols, index+1)\n",
    "                plt.imshow(array[index], cmap=\"gray\", interpolation=\"nearest\")\n",
    "                plt.axis('off')\n",
    "        plt.show()\n",
    " \n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJMEStIMmkLq",
    "colab_type": "text"
   },
   "source": [
    "#### 数据的预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A9q7sr81mmgq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 同pytorch\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def raw_file_idx3_process(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        binary_data = f.read()\n",
    "        off_set = 0\n",
    "        fmt_header = '>iiii'\n",
    "        magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, binary_data, off_set)\n",
    "\n",
    "        image_size = num_rows * num_cols\n",
    "        off_set += struct.calcsize(fmt_header)\n",
    "        fmt_image = '>' + str(image_size) + 'B'\n",
    "        images = np.empty((num_images, 1,  num_rows, num_cols))\n",
    "\n",
    "        print(\"\\nfile idx3 decoding:\")\n",
    "        b = Progress_bar()\n",
    "        for i in range(num_images):\n",
    "            b.bar(i, num_images, \"Preprocessed \")\n",
    "            temp = np.array(struct.unpack_from(fmt_image, binary_data, off_set)).reshape((num_rows, num_cols)).reshape(-1,1)\n",
    "            temp = temp / 255\n",
    "            temp = temp.reshape(1, 28, 28)\n",
    "            images[i][0] = temp\n",
    "            off_set += struct.calcsize(fmt_image)\n",
    "    return images"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-UP_DVXtmoxL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 同pytorch\n",
    "def raw_file_idx1_process(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        binary_data = f.read()\n",
    "        off_set = 0\n",
    "        fmt_header = '>ii'\n",
    "        magic_number, num_labels = struct.unpack_from(fmt_header, binary_data, off_set)\n",
    "\n",
    "        off_set += struct.calcsize(fmt_header)\n",
    "        fmt_label = '>B'\n",
    "        labels = np.empty(num_labels)\n",
    "\n",
    "        print(\"\\nfile idx1 decoding:\")\n",
    "        b = Progress_bar()\n",
    "        for i in range(num_labels):\n",
    "            b.bar(i, num_labels, \"Preprocessed \")\n",
    "            labels[i] = np.array(struct.unpack_from(fmt_label, binary_data, off_set), dtype=np.int)\n",
    "            off_set += struct.calcsize(fmt_label)\n",
    "    return labels"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji9uSPgtmuVg",
    "colab_type": "text"
   },
   "source": [
    "#### Tensorflow 数据处理 构建dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Su6HG6iTmxtS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 构建数据集\n",
    "import tensorflow as tf\n",
    "def reader_dataset(data_file, label_file, idx3=True, batch_size=128, shuffle_buffer_size=10000):\n",
    "    '''\n",
    "    :param data_file: 图像数据文件\n",
    "    :param label_file:  标签文件\n",
    "    :param idx3: 是否是idx3格式 默认是\n",
    "    :param batch_size: 批处理的参数\n",
    "    :param shuffle_buffer_size: 随机打乱的参数\n",
    "    :return: 数据集\n",
    "    '''\n",
    "    data_array = raw_file_idx3_process(data_file)\n",
    "    label_array = raw_file_idx1_process(label_file)\n",
    "    # 调整格式\n",
    "    if idx3:\n",
    "        data_array = data_array.reshape(-1, 1).reshape(60000, 28, 28, -1)\n",
    "    else:\n",
    "        data_array = data_array.reshape(-1, 1).reshape(10000, 28, 28, -1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data_array, label_array))\n",
    "    # 重复\n",
    "    dataset = dataset.repeat()\n",
    "    # 打乱\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size).batch(batch_size)\n",
    "    return dataset\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eboZkei7m4iY",
    "colab_type": "text"
   },
   "source": [
    "#### Tendorflow 构建数据\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f0ZPk09Wm8_F",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "outputId": "dd07c7e9-8880-4412-85d7-2d53f0745301"
   },
   "source": [
    "# 数据集 训练和测试\n",
    "BATCH_SIZE = 128\n",
    "train_set = reader_dataset(train_data_file, train_label_file)\n",
    "test_set = reader_dataset(test_data_file, test_label_file, idx3=False)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "file idx3 decoding:\n",
      "Preprocessed : ==========================>  time left:0.00s 60000/60000  100.00 % time cost:26.34s \n",
      "file idx1 decoding:\n",
      "Preprocessed : ==========================>  time left:0.00s 60000/60000  100.00 % time cost:16.32s \n",
      "file idx3 decoding:\n",
      "Preprocessed : ==========================>  time left:0.00s 10000/10000  100.00 % time cost:4.32s \n",
      "file idx1 decoding:\n",
      "Preprocessed : ==========================>  time left:0.00s 10000/10000  100.00 % time cost:2.62s "
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVLXsB8PnC0L",
    "colab_type": "text"
   },
   "source": [
    "### Tensorflow 构建keras模型"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "coOod9xwngIw",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "outputId": "25afc82d-7023-46f9-9621-b70baeab0acd"
   },
   "source": [
    "import tensorflow.keras as keras\n",
    "'''\n",
    "    第一卷积层\n",
    "    池化\n",
    "    第二卷积层\n",
    "    池化\n",
    "    展平\n",
    "    线性全连接层\n",
    "    线性全连接层 \n",
    "'''\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"valid\", input_shape=(28, 28, 1), activation='relu'),\n",
    "    keras.layers.MaxPool2D((2, 2)),\n",
    "    keras.layers.Conv2D(filters=50, kernel_size=(5, 5), padding=\"valid\", activation='relu'),\n",
    "    keras.layers.MaxPool2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(500, activation='relu'),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.summary()"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 20)        520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 50)          25050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               400500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 431,080\n",
      "Trainable params: 431,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bl5bpFhnnqap",
    "colab_type": "text"
   },
   "source": [
    "#### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iLI0IdccnvHR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "outputId": "746252f2-a031-4573-ca5d-effc850553e4"
   },
   "source": [
    "model.compile(\n",
    "    optimizer=\"sgd\",\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "history = model.fit(train_set,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=60000//BATCH_SIZE,\n",
    "                    validation_steps=10000//BATCH_SIZE,\n",
    "                    validation_data=test_set)\n"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Train for 468 steps, validate for 78 steps\n",
      "Epoch 1/5\n",
      "468/468 [==============================] - 11s 24ms/step - loss: 1.0245 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.3316 - val_sparse_categorical_accuracy: 0.9006\n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2681 - sparse_categorical_accuracy: 0.9198 - val_loss: 0.2173 - val_sparse_categorical_accuracy: 0.9356\n",
      "Epoch 3/5\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1934 - sparse_categorical_accuracy: 0.9422 - val_loss: 0.1606 - val_sparse_categorical_accuracy: 0.9535\n",
      "Epoch 4/5\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1488 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.1270 - val_sparse_categorical_accuracy: 0.9621\n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1237 - sparse_categorical_accuracy: 0.9630 - val_loss: 0.1039 - val_sparse_categorical_accuracy: 0.9681\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSMUO9XktDEo",
    "colab_type": "text"
   },
   "source": [
    "#### 模型评价"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OFht2BTfs_wV",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "outputId": "9ea95bad-59cc-4f6b-a3f2-87e44ad2f2eb"
   },
   "source": [
    "model.evaluate(test_set,steps=10000//BATCH_SIZE, verbose=2)"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "78/78 - 1s - loss: 0.1042 - sparse_categorical_accuracy: 0.9670\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.10416623271810703, 0.9670473]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 16
    }
   ]
  }
 ]
}